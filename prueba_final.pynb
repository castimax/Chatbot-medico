{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r \"../requirements2.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Celda 1: Definir y Limpiar los Documentos\n",
    "\n",
    "Este código descarga un archivo desde GitHub, lo guarda temporalmente, lo carga y limpia su contenido eliminando caracteres especiales y etiquetas HTML innecesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Cargar las variables de entorno desde el archivo .env\n",
    "load_dotenv()\n",
    "\n",
    "# Usar root como base del GitHub\n",
    "root = os.getenv(\"ROOT\")\n",
    "if not root:\n",
    "    raise ValueError(\"ROOT no encontrado en el archivo .env\")\n",
    "\n",
    "print(\"Root de GitHub:\", root)\n",
    "\n",
    "# URL del archivo en GitHub\n",
    "file_path = f\"{root}/documentos_y_matcomplement/docuentreno/md/Cholesterol-Myths-vs-Facts-Spanish.md\"\n",
    "print(\"URL del archivo:\", file_path)\n",
    "\n",
    "# Descargar el contenido del archivo\n",
    "response = requests.get(file_path)\n",
    "if response.status_code != 200:\n",
    "    raise RuntimeError(f\"Error al descargar el archivo desde {file_path}\")\n",
    "\n",
    "# Guardar el contenido en un archivo temporal\n",
    "with open(\"temp.md\", \"w\", encoding=\"utf-8\") as temp_file:\n",
    "    temp_file.write(response.text)\n",
    "\n",
    "# Cargar el documento .md desde el archivo temporal\n",
    "text_loader = TextLoader(\"temp.md\")\n",
    "documents = text_loader.load()\n",
    "\n",
    "# Limpiar el contenido del documento\n",
    "def clean_text(text):\n",
    "    # Eliminar caracteres especiales no deseados\n",
    "    text = text.replace('\\ufeff', '')\n",
    "    text = text.replace('<a name=\"br1\"></a>', '')\n",
    "    return text.strip()\n",
    "\n",
    "# Procesar y limpiar el contenido del documento\n",
    "cleaned_documents = []\n",
    "for doc in documents:\n",
    "    cleaned_text = clean_text(doc.page_content)\n",
    "    cleaned_documents.append(cleaned_text)\n",
    "\n",
    "# Mostrar el contenido limpio del documento\n",
    "for doc in cleaned_documents:\n",
    "    print(\"Contenido limpio del documento:\", doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Celda 2: Crear los Embeddings\n",
    "\n",
    "Este código inicializa un modelo de embeddings utilizando `HuggingFaceEmbeddings`, genera embeddings para cada documento limpio y los imprime para su análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Embedding Using Huggingface\n",
    "huggingface_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\",  # Puedes cambiar esto a \"sentence-transformers/all-MiniLM-l6-v2\" si lo prefieres\n",
    "    model_kwargs={'device': 'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n",
    "\n",
    "# Crear embeddings para el contenido limpio del documento\n",
    "embeddings = []\n",
    "for doc in cleaned_documents:\n",
    "    embedding = huggingface_embeddings.embed_documents([doc])\n",
    "    embeddings.append(embedding)\n",
    "\n",
    "# Imprimir los embeddings para análisis\n",
    "for idx, embedding in enumerate(embeddings):\n",
    "    print(f\"Embeddings del documento {idx + 1}: {embedding}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Celda 3: Crear Embeddings de una Consulta\n",
    "\n",
    "Utiliza el método `embed_query` para crear embeddings a partir del contenido del primer documento limpio.\n",
    "Convierte los embeddings a un array de NumPy y muestra el array y su forma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Crear embeddings para una consulta específica del primer documento limpio\n",
    "query_embedding = huggingface_embeddings.embed_query(cleaned_documents[0])\n",
    "\n",
    "# Mostrar los embeddings como un array de NumPy y su forma\n",
    "print(np.array(query_embedding))\n",
    "print(np.array(query_embedding).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Celda 4: Creación del VectorStore\n",
    "\n",
    "Utiliza `FAISS` para crear un `VectorStore` a partir de los documentos finales y los embeddings generados, incluyendo metadatos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import Document  # Importar la clase Document desde langchain.schema\n",
    "\n",
    "# Crear objetos de documento adecuados a partir de las cadenas de texto limpias con metadatos\n",
    "final_documents = [Document(page_content=content, metadata={\"source\": f\"Documento {i+1}\"}) for i, content in enumerate(cleaned_documents[:120])]\n",
    "\n",
    "# Crear el VectorStore utilizando FAISS y los embeddings generados\n",
    "vectorstore = FAISS.from_documents(final_documents, huggingface_embeddings)\n",
    "\n",
    "# Verificación del VectorStore creado\n",
    "print(\"VectorStore creado con éxito:\", vectorstore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Celda 5: Realizar una Consulta Usando Búsqueda por Similaridad\n",
    "\n",
    "Esta celda utiliza el `VectorStore` para realizar una búsqueda por similaridad basándose en una consulta específica. Luego, imprime el contenido del documento más relevante encontrado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Query using Similarity Search\n",
    "query = \"TENGO ALTO EL COLESTEROL QUE DEBO HACER, TENGO 35 AÑOS\"\n",
    "relevant_documents = vectorstore.similarity_search(query)\n",
    "\n",
    "print(relevant_documents[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Celda 6: Configurar el Retriever\n",
    "\n",
    "Configura un `Retriever` a partir del `VectorStore` utilizando búsqueda por similaridad y muestra su configuración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configurar el Retriever\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "\n",
    "# Realizar una consulta usando el Retriever\n",
    "query = \"TENGO ALTO EL COLESTEROL QUE DEBO HACER, TENGO 35 AÑOS\"\n",
    "relevant_documents = retriever.get_relevant_documents(query)\n",
    "\n",
    "# Imprimir el contenido relevante y sus metadatos\n",
    "for idx, doc in enumerate(relevant_documents):\n",
    "    print(f\"Documento relevante {idx + 1}:\")\n",
    "    print(f\"Fuente: {doc.metadata['source']}\")\n",
    "    print(f\"Contenido: {doc.page_content}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
